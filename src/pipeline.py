import sys
import cv2
import os
from sys import platform
import argparse
import time
import progress.bar as progress_bar
import utils.graph_parser as gp

# Import OpenPose python wrapper
try:
    dir_path = os.path.dirname(os.path.realpath(__file__))
    # Windows Import
    if platform == "win32":
        sys.path.append(
            dir_path + '../openpose/build/python/openpose/Release'
        )
        path = os.environ['PATH'] + ';' + \
            dir_path + '/../../x64/Release;' + \
            dir_path + '/../../bin;'
        os.environ['PATH'] = path
        import pyopenpose as op
    else:
        # OSX/Linux
        sys.path.append('/usr/local/python')
        from openpose import pyopenpose as op
except ImportError as e:
    print('Error during openpose import!')
    raise e


def parse_config_params(arguments):
    """
    Given the size of the arguments passed, parses the custom parameters
    passed as command line options, and returns a dictionary of
    parameters
    :param arguments: size of arguments
    :return dict: dictionary of parameters
    """
    parameters = dict()
    arg_size = len(arguments[1])
    for i in range(0, arg_size):
        curr_keyword = arguments[1][i]
        # if the current keyword is not the last one
        if i != arg_size - 1:
            next_keyword = arguments[1][i + 1]
        else:
            next_keyword = '1'
        if '--' in curr_keyword:
            keyword = curr_keyword.replace('-', '')
            if keyword not in parameters:
                if '--' in next_keyword:
                    parameters[keyword] = '1'
                else:
                    parameters[keyword] = next_keyword
    return parameters


def write_json(obj, node_type: dict, frame_path: str, resolution: str,
               index: int = None):
    """
    Given a Datum obj, a dict of parameters, an frame path, a resolution
    and optionally an index, parses the keypoints generated by OpenPose
    and saves the values as JSON
    :param obj: Datum obj(look to OpenPose doc)
    :param dict node_type: dictionary of flags, representing which type
    of nodes were processed
    :param str frame_path: path of a frame/image
    :param str resolution: resolution of the video/image
    :param int index: counter of frames, used for file naming in case of
    a video processing
    """
    keypts_list = []
    # Pose
    if node_type['pose']:
        keypts_list = [obj.poseKeypoints]
    # Face
    if node_type['face']:
        keypts_list.append(obj.faceKeypoints)
    # Hand
    if node_type['hand']:
        keypts_list.append(obj.handKeypoints[0])
        keypts_list.append(obj.handKeypoints[1])
    # Request to write the output as json
    gp.points_to_json(keypts_list,
                      args[0].write_json,
                      resolution,
                      node_type,
                      str(os.path.splitext(frame_path)[0].split('/')[-1]),
                      index)


def display_img(img):
    """
    Given an image represented as a numpy array of rgb values, displays
    the image processed by OpenPose
    :param img: numpy n array of rgb values
    :return None: In order to stop the
    """
    cv2.imshow("OpenPose Image", img)
    key = cv2.waitKey(15)
    if key == 27:
        return None


def process_images(image_paths: str, node_types: dict):
    """
    Given a path to a folder containing images, applies OpenPose image
    processing to each image in the path, and perform other operations
    based on the flags passed as arguments in command line
    :param image_paths: path to a folder containing images
    :param node_types: dictionary of flags that represents the type of
    nodes to be processed
    """
    bar = progress_bar.IncrementalBar(
        'Applying OpenPose recognition: ',
        max=len(image_paths),
        suffix='%(index)d/%(max)d'
    )
    start = time.time()
    bar.start()
    for image_path in image_paths:
        datum = op.Datum()
        image_to_process = cv2.imread(image_path)
        datum.cvInputData = image_to_process

        if node_types['hand'] and not node_types['pose']:
            a = image_to_process.shape[0]
            b = image_to_process.shape[1]
            hand_rectangles = [
                [
                    op.Rectangle(0., a / 2 - b / 2, a, a),
                    op.Rectangle(0., a / 2 - b / 2, a, a),
                ]
            ]
            datum.handRectangles = hand_rectangles

        opWrapper.emplaceAndPop([datum])
        bar.next()
        if args[0].display == '1':
            img = datum.cvOutputData
            if node_types['hand'] and not node_types['pose']:
                a = image_to_process.shape[0]
                b = image_to_process.shape[1]
                img = cv2.rectangle(datum.cvOutputData,
                                    (0, int(a/2 - b/2)),
                                    (b, int(b + a/2 - b/2)),
                                    (0, 255, 0),
                                    10)
            display_img(img)
        if args[0].write_json is not None:
            write_json(datum, node_types, image_path, image_to_process.shape)
    bar.finish()
    end = time.time()
    print("Image processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def process_video(video_path: str, node_type: dict):
    """
    Given a path to a video, applies OpenPose image processing to each
    frame of the video, and perform other operations based on the flags
    passed as arguments in command line
    :param str video_path: a path to a video file
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    video = cv2.VideoCapture(video_path)
    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    if n_frames == 0:
        raise FileNotFoundError(video_path + ' not found!')
    bar = progress_bar.IncrementalBar(
        'Applying OpenPose recognition: ',
        max=n_frames,
        suffix='%(index)d/%(max)d'
    )
    start = time.time()
    bar.start()
    frame_index = 0
    datum = op.Datum()
    while video.isOpened():
        ret, video_frame = video.read()
        if ret:
            datum.cvInputData = video_frame
            opWrapper.emplaceAndPop([datum])
            bar.next()
            if args[0].display == '1':
                display_img(datum.cvOutputData)
            if args[0].write_json is not None:
                write_json(datum,
                           node_type,
                           video_path,
                           video_frame.shape,
                           frame_index)
                frame_index += 1
    bar.finish()
    end = time.time()
    print("Video processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def process_stream(node_type: dict):
    """
    Applies OpenPose image processing to an input stream such as a
    camera, and perform other operations based on the flags passed as
    arguments in command line
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    stream = cv2.VideoCapture(0)
    datum = op.Datum()
    frame_index = 0
    fps_count = 0
    start = time.time()
    while True:
        ret, frame = stream.read()
        if ret:
            datum.cvInputData = frame
            opWrapper.emplaceAndPop([datum])
            if args[0].write_json is not None:
                write_json(datum,
                           node_type,
                           'capture.jpeg',
                           frame.shape,
                           frame_index)
                frame_index += 1
            fps_count += 1
            fps_value = fps_count/(time.time() - start)
            print('Current FPS: ' + str(fps_value), end='\r')
            image = cv2.putText(datum.cvOutputData,
                                str(round(fps_value, 2)) + ' FPS',
                                (50, 50),
                                cv2.FONT_HERSHEY_SIMPLEX,
                                1,
                                (57, 255, 20),
                                2, cv2.LINE_AA)
            cv2.imshow("OpenPose stream", image)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    stream.release()
    cv2.destroyAllWindows()


def get_node_types(arguments: dict):
    """
    Given the arguments parsed from command line, returns a dictionary
    of flags representing the node types to be processed
    :param dict arguments: dictionary of arguments parsed from command
    line
    :return: dictionary of node types
    """
    out = dict(pose=False, hand=False, face=False)
    # check if only face or only hand is required
    if 'body' in arguments and arguments['body'] == '0':
        # only hand
        if 'hand' in arguments and 'face' not in arguments:
            out['hand'] = True
            return out
        # only face
        elif 'face' in arguments and 'hand' not in arguments:
            out['face'] = True
            return out
        else:
            raise RuntimeError('--hand and --face cannot be used'
                               'simultaneously with --body 0')
    else:
        out['pose'] = True
        if 'hand' in arguments:
            out['hand'] = True
        if 'face' in arguments:
            out['face'] = True
    return out


if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    # default params
    parser.add_argument('--image_dir')
    parser.add_argument('--video')
    parser.add_argument('--display', default='0')
    parser.add_argument('--write_json')
    args = parser.parse_known_args()
    # Custom params
    params = parse_config_params(args)
    params["model_folder"] = "../openpose/models/"

    # Starting OpenPose
    opWrapper = op.WrapperPython()
    opWrapper.configure(params)
    opWrapper.start()
    node_t = get_node_types(params)

    # video processing
    if args[0].video is not None and args[0].image_dir is None:
        process_video(args[0].video, node_t)

    # image processing
    elif args[0].image_dir is not None and args[0].video is None:
        paths = op.get_images_on_directory(args[0].image_dir)
        process_images(paths, node_t)
    else:
        try:
            # camera processing
            process_stream(node_t)
        except IndexError:
            print('Usage: ' + os.path.basename(__file__) +
                  ' --image_dir [path] or --video [path]')

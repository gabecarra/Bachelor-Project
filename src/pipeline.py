import sys
import cv2
import os
from sys import platform
import importlib
import time
import progress.bar as progress_bar
import utils.graph_parser as gp
from statistics import mean
from math import ceil

# Import OpenPose python wrapper
try:
    dir_path = os.path.dirname(os.path.realpath(__file__))
    # Windows Import
    if platform == "win32":
        sys.path.append(
            dir_path + '../openpose/build/python/openpose/Release'
        )
        path = os.environ['PATH'] + ';' + \
            dir_path + '/../../x64/Release;' + \
            dir_path + '/../../bin;'
        os.environ['PATH'] = path
        import pyopenpose as op
    else:
        # OSX/Linux
        sys.path.append('/usr/local/python')
        from openpose import pyopenpose as op
except ImportError as e:
    print('Error during openpose import!')
    raise e


# ---HELPER FUNCTIONS---

def __parse_args(args: list) -> (dict, dict):
    """
    Given all the passed arguments, represented as a list of the type
    ['--arg1', '--arg2', ...], separate default and custom arguments,
    parse them, and return a dictionary of parsed default args and
    a dictionary of custom args
    :param list args: list of arguments
    :return (dict, dict): 2 dictionaries of parsed arguments, one for
    default and another for custom
    """
    args = [x.split(' ') for x in args]
    default_dict = dict(display='0',
                        image_dir=None,
                        video=None,
                        write_json=None)
    default = ['--write_json',
               '--video',
               '--image_dir',
               '--display']
    custom_list = []
    default_list = []
    for i in range(len(args)):
        if args[i][0] in default:
            [default_list.append(x) for x in args[i]]
        else:
            [custom_list.append(x) for x in args[i]]
    custom_dict = __generate_args_dict(custom_list)
    temp_dict = __generate_args_dict(default_list)
    for key in default_dict.keys():
        if key in temp_dict.keys():
            default_dict[key] = temp_dict[key]
    return default_dict, custom_dict


def __generate_args_dict(args: list) -> dict:
    """
    Given a list of arguments, parse them and returns a dictionary of
    parsed arguments
    :param list args: list of arguments
    :return dict: dictionary of parsed arguments
    """
    args_dict = dict()
    args_size = len(args)
    for i in range(0, args_size):
        curr_keyword = args[i]
        # if the current keyword is not the last one
        if i != args_size - 1:
            next_keyword = args[i + 1]
        else:
            next_keyword = '1'
        if '--' in curr_keyword:
            keyword = curr_keyword.replace('-', '')
            if keyword not in args_dict:
                if '--' in next_keyword:
                    args_dict[keyword] = '1'
                else:
                    args_dict[keyword] = next_keyword
    return args_dict


def __generate_bar(text: str, size: int):
    """
    Generates a loading bar for tracking OpenPose processing operations
    :param str text: string that will be printed before the progress bar
    :param size: length of the progress bar(n of elements)
    :return:
    """
    return progress_bar.IncrementalBar(
        text,
        max=size,
        suffix='%(index)d/%(max)d'
    )


def __write_json(datum, node_type: dict, filename: str, res: list, out_path: str):
    """
    Parses the keypoints generated by OpenPose and saves the values as
    JSON graph representation
    :param datum: instance of OpenPose datum class (see OpenPose doc)
    :param dict node_type: dictionary of flags, representing which type
    of nodes have been processed
    :param str filename: name of a frame/image
    :param list res: resolution of the video/image. resolution[0]
    represents axis x, resolution[1] represents axis y
    :param str out_path: output path
    """
    keypts_list = []
    # Pose
    if node_type['pose']:
        keypts_list = [datum.poseKeypoints]
    # Face
    if node_type['face']:
        keypts_list.append(datum.faceKeypoints)
    # Hand
    if node_type['hand']:
        keypts_list.append(datum.handKeypoints[0])
        keypts_list.append(datum.handKeypoints[1])
    # Request to write the output as json
    gp.points_to_json(keypts_list,
                      out_path,
                      res,
                      node_type,
                      filename)


def __display_img(img):
    """
    Given an image represented as a numpy array of rgb values, displays
    the image processed by OpenPose
    :param img: numpy n array of rgb values
    :return None: In order to stop the
    """
    cv2.imshow('image', img)
    key = cv2.waitKey(1000)
    if key == 27:
        cv2.destroyAllWindows()


def __display_fps(fps_count: int, start, output):
    """
    Adds the fps counter to the left top corner of the stream
    :param int fps_count: number of frames processed
    :param start: the time when the stream started
    :param output: the OpenPose output image
    :return: the output image with the fps counter + prints it in
    console
    """
    fps_value = fps_count / (time.time() - start)
    # print('Current FPS: ' + str(fps_value), end='\r')
    return cv2.putText(output,
                       str(round(fps_value, 2)) + ' FPS',
                       (50, 50),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       1,
                       (57, 255, 20),
                       2, cv2.LINE_AA)


def __get_node_types(args: dict):
    """
    Given the parsed arguments, returns a dictionary of flags
    representing the node types to be processed
    :param dict args: dictionary of parsed args
    :return: dictionary of node types
    """
    out = dict(pose=False, hand=False, face=False)
    # check if only face or only hand is required
    if 'body' in args and args['body'] == '0':
        # only hand
        if 'hand' in args and 'face' not in args or args['face'] == '0':
            out['hand'] = True
            return out
        # only face
        elif 'face' in args and 'hand' not in args or args['hand'] == '0':
            out['face'] = True
            return out
        else:
            raise RuntimeError('--hand and --face cannot be used'
                               'simultaneously with --body 0')
    else:
        out['pose'] = True
        if 'hand' in args:
            out['hand'] = True
        if 'face' in args:
            out['face'] = True
    return out


def __get_hands_img(img, keypts):
    """
    Draw the keypoints generated by OpenPose on the given image, and
    returns it
    :param img: image given as a n array of rgb values
    :param keypts: keypoints of the hand
    :return: image processed as rbg n array
    """
    # node colors in bgr
    colors = [(100, 100, 100),
              (0, 0, 100),
              (0, 0, 150),
              (0, 0, 200),
              (0, 0, 255),
              (0, 100, 100),
              (0, 150, 150),
              (0, 200, 200),
              (0, 255, 255),
              (50, 100, 0),
              (75, 150, 0),
              (100, 200, 0),
              (125, 255, 0),
              (100, 50, 0),
              (150, 75, 0),
              (200, 100, 0),
              (255, 125, 0),
              (100, 0, 100),
              (150, 0, 150),
              (200, 0, 200),
              (255, 0, 255)]
    for i in range(1, 21, 4):
        img = cv2.line(img,
                       (keypts[0][0][0], keypts[0][0][1]),
                       (keypts[0][i][0], keypts[0][i][1]),
                       colors[i],
                       ceil(img.shape[1] * 0.015),
                       lineType=cv2.LINE_AA)
        for j in range(i, i + 3):
            img = cv2.line(img,
                           (keypts[0][j][0], keypts[0][j][1]),
                           (keypts[0][j + 1][0], keypts[0][j + 1][1]),
                           colors[j + 1],
                           ceil(img.shape[1] * 0.015),
                           lineType=cv2.LINE_AA)
    for i in range(len(keypts[0])):
        img = cv2.circle(img,
                         (keypts[0][i][0], keypts[0][i][1]),
                         ceil(img.shape[1] * 0.017),
                         colors[i],
                         -1,
                         lineType=cv2.LINE_AA)
    return img


# ---OPENPOSE PROCESSING---


def __process_images(openpose, args: dict, node_type: dict):
    """
    Process an image or a set of images as specified in the args, in
    order to get the prediction of keypoints for face, hands and body,
    as indicated by node_type
    :param openpose: OpenPose wrapper
    :param dict args: dictionary of default arguments
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    image_paths = op.get_images_on_directory(args['image_dir'])
    bar = __generate_bar('Applying image processing: ', len(image_paths))
    start = time.time()
    for image_path in image_paths:
        datum = op.Datum()
        image_to_process = cv2.imread(image_path)
        datum.cvInputData = image_to_process
        openpose.emplaceAndPop([datum])
        bar.next()
        if args['display'] == '1':
            __display_img(datum.cvOutputData)
        if args['write_json']:
            filename = str(os.path.splitext(image_path)[0].split('/')[-1])
            __write_json(datum,
                         node_type,
                         filename,
                         image_to_process.shape,
                         args['write_json'])
    bar.finish()
    end = time.time()
    print("Image processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def __process_hands(openpose, args):
    """
    Applies hands processing to an image or a set of images as specified
    in the args, in order to get the prediction of its keypoints
    :param openpose: OpenPose wrapper
    :param dict args: dictionary of default arguments
    """
    image_paths = op.get_images_on_directory(args['image_dir'])
    bar = __generate_bar('Applying hands recognition: ', len(image_paths))
    start = time.time()
    idx = 0
    for image_path in image_paths:
        datum = op.Datum()
        image_to_process = cv2.imread(image_path)
        datum.cvInputData = image_to_process
        a = image_to_process.shape[0]
        b = image_to_process.shape[1]
        hand_rectangles = [
            [
                op.Rectangle(0., a / 2 - b / 2, a, a),
                op.Rectangle(0., a / 2 - b / 2, a, a),
            ]
        ]
        datum.handRectangles = hand_rectangles
        openpose.emplaceAndPop([datum])
        bar.next()
        left = datum.handKeypoints[0]
        right = datum.handKeypoints[1]
        left_is_best = mean(left[0][:, 2]) >= mean(right[0][:, 2])
        keypts = left if left_is_best else right
        if args['display'] == '1':
            img = __get_hands_img(image_to_process, keypts)
            __display_img(img)
        if args['write_images']:
            ext = os.path.splitext(image_path)[1]
            out_path = args['write_images'][: args['write_images'].rfind('/')] + \
                '/' + str(idx) + '_rendered' + ext
            img = __get_hands_img(image_to_process, keypts)
            try:
                os.mkdir(args['write_images'])
            except FileExistsError:
                pass
            cv2.imwrite(out_path, img)
            idx += 1
        if args['write_json']:
            filename = str(os.path.splitext(image_path)[0].split('/')[-1])
            __write_json(datum,
                         dict(hand=True, face=False, pose=False),
                         filename,
                         image_to_process.shape,
                         args['write_json'])
    bar.finish()
    end = time.time()
    print("Hands processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def __process_video(openpose, args, node_type: dict):
    """
    Process an video in order to get the prediction of keypoints for
    face, hands and body, as indicated by node_types
    :param openpose: OpenPose wrapper
    :param dict args: dictionary of default arguments
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    video = cv2.VideoCapture(args['video'])
    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    if n_frames == 0:
        raise FileNotFoundError(args['video'] + ' not found!')
    bar = progress_bar.IncrementalBar(
        'Applying OpenPose recognition: ',
        max=n_frames,
        suffix='%(index)d/%(max)d'
    )
    start = time.time()
    frame_idx = 0
    while video.isOpened():
        datum = op.Datum()
        ret, video_frame = video.read()
        if ret:
            datum.cvInputData = video_frame
            openpose.emplaceAndPop([datum])
            bar.next()
            if args['display'] == '1':
                __display_img(datum.cvOutputData)
            if args['write_json'] is not None:
                filename = str(os.path.splitext(args['video'])[0].split('/')[-1])
                filename = filename + str(frame_idx)
                __write_json(datum,
                             node_type,
                             filename,
                             video_frame.shape,
                             args['write_json'])
                frame_idx += 1
    bar.finish()
    end = time.time()
    print("Video processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def __process_stream(openpose, args, node_type: dict):
    """
    Applies OpenPose prediction to a stream such as a camera, in order
    to get the prediction of keypoints for face, hands and body, as
    indicated by node_types
    :param openpose: OpenPose wrapper
    :param dict args: dictionary of default arguments
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    stream = cv2.VideoCapture(0)
    datum = op.Datum()
    frame_idx = 0
    fps_count = 0
    start = time.time()
    while True:
        ret, frame = stream.read()
        print(frame, ret)
        if ret:
            datum.cvInputData = frame
            openpose.emplaceAndPop([datum])
            if args['write_json']:
                filename = 'capture' + str(frame_idx)
                __write_json(datum,
                             node_type,
                             filename,
                             frame.shape,
                             args['write_json'])
                frame_idx += 1
            fps_count += 1
            cv2.imshow("OpenPose stream", __display_fps(fps_count,
                                                        start,
                                                        datum.cvOutputData))
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    stream.release()
    cv2.destroyAllWindows()


def parse_data(args):
    default_args, custom_args = __parse_args(args)
    # path to openpose models
    custom_args['model_folder'] = '../openpose/models/'
    node_type = __get_node_types(custom_args)

    # Starting OpenPose
    op_wrapper = op.WrapperPython(0)

    # If i want to process only hands, remove the write_images flag from
    # the config arguments, and insert it to the default ones, since for
    # hands, the image saving is done in a custom way
    if node_type['hand'] and not node_type['pose'] and not node_type['face']:
        default_args['write_images'] = custom_args.pop('write_images', None)
    op_wrapper.configure(custom_args)
    op_wrapper.start()

    usage_err = 'Usage: ' + os.path.basename(__file__) + \
                ' --image_dir [path] or --video [path]'

    # video processing
    if default_args['video']:
        if default_args['image_dir']:
            raise IndexError(usage_err)
        __process_video(op_wrapper, default_args, node_type)

    # image processing
    elif default_args['image_dir']:
        if default_args['video']:
            raise IndexError(usage_err)
        if node_type['hand'] and not node_type['pose']:
            __process_hands(op_wrapper, default_args)
        else:
            __process_images(op_wrapper, default_args, node_type)

    # camera processing
    else:
        try:
            __process_stream(op_wrapper, default_args, node_type)
        except IndexError:
            print(usage_err)
    importlib.reload(op)


if __name__ == '__main__':

    pose_args = ['--image_dir ../src/samples/',
                 '--hand',
                 '--face',
                 '--write_images ../out_img/default/',
                 '--write_json ../out/default/']

    video_args = ['--video ../src/samples/video.mp4',
                  '--write_json ../out/video/',
                  '--hand',
                  '--face',
                  '--write_images ../out_img/video/']
    # only hands
    only_hands_args = ['--image_dir ../src/samples/hand/paper/',
                       '--hand',
                       '--body 0',
                       '--hand_detector 2',
                       '--write_images ../out_img/only_hands/',
                       '--write_json ../out/only_hands/']
    camera_args = ['--hand',
                   '--face',
                   '--write_json ../out/stream/']
    parse_data(camera_args)


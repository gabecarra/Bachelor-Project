import sys
import cv2
import os
from sys import platform
import argparse
import time
import progress.bar as progress_bar
import utils.graph_parser as gp
from statistics import mean
from math import ceil

# Import OpenPose python wrapper
try:
    dir_path = os.path.dirname(os.path.realpath(__file__))
    # Windows Import
    if platform == "win32":
        sys.path.append(
            dir_path + '../openpose/build/python/openpose/Release'
        )
        path = os.environ['PATH'] + ';' + \
            dir_path + '/../../x64/Release;' + \
            dir_path + '/../../bin;'
        os.environ['PATH'] = path
        import pyopenpose as op
    else:
        # OSX/Linux
        sys.path.append('/usr/local/python')
        from openpose import pyopenpose as op
except ImportError as e:
    print('Error during openpose import!')
    raise e


# ---HELPER FUNCTIONS---


def generate_bar(text: str, size: int):
    """
    Generates a loading bar for tracking OpenPose processing operations
    :param str text: string that will be printed before the progress bar
    :param size: length of the progress bar(n of elements)
    :return:
    """
    return progress_bar.IncrementalBar(
        text,
        max=size,
        suffix='%(index)d/%(max)d'
    )


def parse_config_params(arguments):
    """
    Given the size of the arguments passed, parses the custom parameters
    passed as command line options, and returns a dictionary of
    parameters
    :param arguments: size of arguments
    :return dict: dictionary of parameters
    """
    parameters = dict()
    arg_size = len(arguments[1])
    for i in range(0, arg_size):
        curr_keyword = arguments[1][i]
        # if the current keyword is not the last one
        if i != arg_size - 1:
            next_keyword = arguments[1][i + 1]
        else:
            next_keyword = '1'
        if '--' in curr_keyword:
            keyword = curr_keyword.replace('-', '')
            if keyword not in parameters:
                if '--' in next_keyword:
                    parameters[keyword] = '1'
                else:
                    parameters[keyword] = next_keyword
    return parameters


def write_json(obj, node_type: dict, filename: str, res: list, out_path: str):
    """
    Parses the keypoints generated by OpenPose and saves the values as
    JSON
    :param obj: Datum obj(look at OpenPose doc)
    :param dict node_type: dictionary of flags, representing which type
    of nodes have been processed
    :param str filename: name of a frame/image
    :param list res: resolution of the video/image. resolution[0]
    represents axis x, resolution[1] represents axis y
    :param str out_path: output path
    """
    keypts_list = []
    # Pose
    if node_type['pose']:
        keypts_list = [obj.poseKeypoints]
    # Face
    if node_type['face']:
        keypts_list.append(obj.faceKeypoints)
    # Hand
    if node_type['hand']:
        keypts_list.append(obj.handKeypoints[0])
        keypts_list.append(obj.handKeypoints[1])
    # Request to write the output as json
    gp.points_to_json(keypts_list,
                      out_path,
                      res,
                      node_type,
                      filename)


def display_img(img):
    """
    Given an image represented as a numpy array of rgb values, displays
    the image processed by OpenPose
    :param img: numpy n array of rgb values
    :return None: In order to stop the
    """
    cv2.imshow("OpenPose Image", img)
    key = cv2.waitKey(15)
    if key == 27:
        return None


def display_fps(fps_count: int, start, output):
    """
    Adds the fps counter to the left top corner of the stream
    :param int fps_count: number of frames processed
    :param start: the time when the stream started
    :param output: the OpenPose output image
    :return: the output image with the fps counter + prints it in
    console
    """
    fps_value = fps_count / (time.time() - start)
    print('Current FPS: ' + str(fps_value), end='\r')
    return cv2.putText(output,
                       str(round(fps_value, 2)) + ' FPS',
                       (50, 50),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       1,
                       (57, 255, 20),
                       2, cv2.LINE_AA)


def get_node_types(arguments: dict):
    """
    Given the arguments parsed from command line, returns a dictionary
    of flags representing the node types to be processed
    :param dict arguments: dictionary of arguments parsed from command
    line
    :return: dictionary of node types
    """
    out = dict(pose=False, hand=False, face=False)
    # check if only face or only hand is required
    if 'body' in arguments and arguments['body'] == '0':
        # only hand
        if 'hand' in arguments and 'face' not in arguments:
            out['hand'] = True
            return out
        # only face
        elif 'face' in arguments and 'hand' not in arguments:
            out['face'] = True
            return out
        else:
            raise RuntimeError('--hand and --face cannot be used'
                               'simultaneously with --body 0')
    else:
        out['pose'] = True
        if 'hand' in arguments:
            out['hand'] = True
        if 'face' in arguments:
            out['face'] = True
    return out


def norm_frame_path(video_path: str, idx: int):
    """
    Normalizes the filename path, adding needed 0s to the string
    :param video_path: the path of the video
    :param idx: the index of the current frame
    :return:
    """
    dot = video_path.rfind('.')
    zeros = '0' if idx < 10 else ''
    return video_path[:dot] + zeros + str(idx) + video_path[dot:]


def get_hands_img(img, keypts):
    """
    Draw the keypoints on the given image
    :param img: image given as a n array of rgb values
    :param keypts: keypoints of the left hand
    :return: image processed as rbg n array
    """
    for elem in keypts[0]:
        img = cv2.circle(img,
                         (elem[0], elem[1]),
                         ceil(img.shape[1] * 0.013),
                         (255, 255, 255),
                         -1,
                         lineType=cv2.LINE_AA)
    for i in range(1, 21, 4):
        img = cv2.line(img,
                       (keypts[0][0][0], keypts[0][0][1]),
                       (keypts[0][i][0], keypts[0][i][1]),
                       (255, 255, 255),
                       ceil(img.shape[1] * 0.01),
                       lineType=cv2.LINE_AA)
        for j in range(i, i + 3):
            img = cv2.line(img,
                           (keypts[0][j][0], keypts[0][j][1]),
                           (keypts[0][j + 1][0], keypts[0][j + 1][1]),
                           (255, 255, 255),
                           ceil(img.shape[1] * 0.01),
                           lineType=cv2.LINE_AA)
    return img


# ---OPENPOSE PROCESSING---


def process_images(args, node_types: dict):
    """
    Given a path to a folder containing images, applies OpenPose image
    processing to each image in the path, and perform other operations
    based on the flags passed as arguments in command line
    :param args: arguments given as input to OpenPose
    :param node_types: dictionary of flags that represents the type of
    nodes to be processed
    """
    image_paths = op.get_images_on_directory(args.image_dir)
    bar = generate_bar('Applying OpenPose recognition: ', len(image_paths))
    start = time.time()
    for image_path in image_paths:
        datum = op.Datum()
        image_to_process = cv2.imread(image_path)
        datum.cvInputData = image_to_process
        opWrapper.emplaceAndPop([datum])
        bar.next()
        if args.display == '1':
            display_img(datum.cvOutputData)
        if args.write_json:
            filename = str(os.path.splitext(image_path)[0].split('/')[-1])
            write_json(datum,
                       node_types,
                       filename,
                       image_to_process.shape,
                       args.write_json)
    bar.finish()
    end = time.time()
    print("Image processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def process_hands(args, node_types: dict):
    """
    Given a path to a folder containing images, applies OpenPose image
    processing to each image in the path, and perform other operations
    based on the flags passed as arguments in command line
    :param args: arguments given as input to OpenPose
    :param node_types: dictionary of flags that represents the type of
    nodes to be processed
    """
    image_paths = op.get_images_on_directory(args.image_dir)
    bar = generate_bar('Applying hands recognition: ', len(image_paths))
    start = time.time()
    idx = 0
    for image_path in image_paths:
        datum = op.Datum()
        image_to_process = cv2.imread(image_path)
        datum.cvInputData = image_to_process
        a = image_to_process.shape[0]
        b = image_to_process.shape[1]
        hand_rectangles = [
            [
                op.Rectangle(0., a / 2 - b / 2, a, a),
                op.Rectangle(0., a / 2 - b / 2, a, a),
            ]
        ]
        datum.handRectangles = hand_rectangles
        opWrapper.emplaceAndPop([datum])
        bar.next()
        left = datum.handKeypoints[0]
        right = datum.handKeypoints[1]
        left_is_best = mean(left[0][:, 2]) >= mean(right[0][:, 2])
        keypts = left if left_is_best else right
        if args.display == '1':
            img = get_hands_img(image_to_process, keypts)
            display_img(img)
        if args.write_images:
            ext = os.path.splitext(image_path)[1]
            out_path = args.write_images[: args.write_images.rfind('/')] + \
                '/' + str(idx) + '_rendered' + ext
            img = get_hands_img(image_to_process, keypts)
            try:
                os.mkdir(args.write_images)
            except FileExistsError:
                pass
            cv2.imwrite(out_path, img)
            idx += 1
        if args.write_json:
            filename = str(os.path.splitext(image_path)[0].split('/')[-1])
            write_json(datum,
                       node_types,
                       filename,
                       image_to_process.shape,
                       args.write_json)
    bar.finish()
    end = time.time()
    print("Hands processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def process_video(args, node_type: dict):
    """
    Applies OpenPose image processing to each frame of the video, and
    perform other operations based on the flags passed as arguments in
    command line
    :param args: arguments given as input to OpenPose
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    video = cv2.VideoCapture(args.video)
    n_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    if n_frames == 0:
        raise FileNotFoundError(args.video + ' not found!')
    bar = progress_bar.IncrementalBar(
        'Applying OpenPose recognition: ',
        max=n_frames,
        suffix='%(index)d/%(max)d'
    )
    start = time.time()
    frame_idx = 0
    while video.isOpened():
        datum = op.Datum()
        ret, video_frame = video.read()
        if ret:
            datum.cvInputData = video_frame
            opWrapper.emplaceAndPop([datum])
            bar.next()
            if args.display == '1':
                display_img(datum.cvOutputData)
            if args.write_json is not None:
                norm_path = norm_frame_path(args.video, frame_idx)
                filename = str(os.path.splitext(norm_path)[0].split('/')[-1])
                write_json(datum,
                           node_type,
                           filename,
                           video_frame.shape,
                           args.write_json)
                frame_idx += 1
    bar.finish()
    end = time.time()
    print("Video processing successfully finished. Total time: {:.2f}s"
          .format(end - start))


def process_stream(args, node_type: dict):
    """
    Applies OpenPose image processing to an input stream such as a
    camera, and perform other operations based on the flags passed as
    arguments in command line
    :param args: arguments given as input to OpenPose
    :param dict node_type: dictionary of flags that represents the type
    of nodes to be processed
    """
    stream = cv2.VideoCapture(0)
    datum = op.Datum()
    frame_idx = 0
    fps_count = 0
    start = time.time()
    while True:
        ret, frame = stream.read()
        if ret:
            datum.cvInputData = frame
            opWrapper.emplaceAndPop([datum])
            if args.write_json is not None:
                norm_path = norm_frame_path('capture.jpeg', frame_idx)
                filename = str(os.path.splitext(norm_path)[0])
                write_json(datum,
                           node_type,
                           filename,
                           frame.shape,
                           args[0].write_json)
                frame_idx += 1
            fps_count += 1
            cv2.imshow("OpenPose stream", display_fps(fps_count,
                                                      start,
                                                      datum.cvOutputData))
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    stream.release()
    cv2.destroyAllWindows()


if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    # default params
    parser.add_argument('--image_dir')
    parser.add_argument('--video')
    parser.add_argument('--display', default='0')
    parser.add_argument('--write_json')
    parser.add_argument('--write_images')
    openpose_args = parser.parse_known_args()
    # Custom params
    params = parse_config_params(openpose_args)
    params["model_folder"] = "../openpose/models/"
    node_t = get_node_types(params)

    # Starting OpenPose
    opWrapper = op.WrapperPython()
    if openpose_args[0].write_images:
        if node_t['pose']:
            params['write_images'] = openpose_args[0].write_images
        opWrapper.configure(params)
    opWrapper.start()

    # video processing
    if openpose_args[0].video is not None and \
            openpose_args[0].image_dir is None:
        process_video(openpose_args[0], node_t)

    # image processing
    elif openpose_args[0].image_dir is not None and\
            openpose_args[0].video is None:
        if node_t['hand'] and not node_t['pose']:
            process_hands(openpose_args[0], node_t)
        else:
            process_images(openpose_args[0], node_t)
    else:
        try:
            # camera processing
            process_stream(openpose_args[0], node_t)
        except IndexError:
            print('Usage: ' + os.path.basename(__file__) +
                  ' --image_dir [path] or --video [path]')
